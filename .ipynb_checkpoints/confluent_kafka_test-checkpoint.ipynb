{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ed3098-4be0-4143-9a37-928cf44352b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17680f05-b37b-4c3e-96e3-215070c30196",
   "metadata": {},
   "source": [
    "## Kafka Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666dc228-f251-41f9-b0ca-144e0713f76e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca5e46e-3519-48c7-83b8-12edd13f7720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': '172.29.16.101:9092'} #'127.0.0.1:29092'}\n",
    "\n",
    "producer = Producer(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0813a-f6f1-4a02-b16f-2ed0770ea209",
   "metadata": {
    "tags": []
   },
   "source": [
    "### define topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ec7103-c1ff-485b-b109-0df90a9920f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic = 'traffic_data_group7'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac1eb65-6ac9-40e2-9ade-0719380836e1",
   "metadata": {},
   "source": [
    "### send message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b042753b-2e12-467a-836c-50934a5565a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "data = { 'msg': 'traffic data test', 'timestamp': datetime.now().isoformat() }\n",
    "\n",
    "producer.produce(topic, value=json.dumps(data))\n",
    "producer.flush(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5465886f-67d9-4519-88f9-a500a3713cac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "producer.poll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e3e5d4-7ad5-4837-81f1-84f60a4f15b2",
   "metadata": {},
   "source": [
    "## Current Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4a4b95-35df-40d1-842c-688952c27374",
   "metadata": {},
   "source": [
    "Kafka topics act as channels for messages in an event streaming platform. Producers send data streams to specific topics, and consumers subscribe to those topics to receive the data. Imagine them as folders for categorized messages in a constantly flowing river of information. ou can write Python code using the `confluent_kafka.admin` library to programmatically list topics. This approach is useful if you want to integrate topic listing within your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f2153c5-302f-48f0-a701-0d3209f88bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecc1ca80-547a-4c06-9a27-6921b64db105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kadmin = AdminClient(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a3c4f1c-a77b-4e85-bd31-a8c8c3cc258e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wikimedia-changes': TopicMetadata(wikimedia-changes, 1 partitions),\n",
       " 'traffic_data_group7': TopicMetadata(traffic_data_group7, 1 partitions),\n",
       " 'roulette': TopicMetadata(roulette, 1 partitions),\n",
       " 'hello-world': TopicMetadata(hello-world, 1 partitions),\n",
       " 'hello': TopicMetadata(hello, 1 partitions),\n",
       " '__consumer_offsets': TopicMetadata(__consumer_offsets, 50 partitions)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kadmin.list_topics().topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2607a8cb-2563-4b23-9c0d-f7276fea70e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x27363dc7790 state=running>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kadmin.list_consumer_groups()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d0fca-b3c4-41d4-9c99-7fe27c63f264",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Kafka Consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fce9dd5-d477-40f1-bb1b-4a8ddd5663e3",
   "metadata": {},
   "source": [
    "A Kafka consumer is a program that listens for and processes messages from specific Kafka topics. Think of it as an ear in a bustling marketplace, tuned in to receive messages of interest published by producers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eec1a59e-98ba-4f03-a847-8ff5cc3c9ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9199a54e-d71e-4d28-9f73-1cd32aba7b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': '172.29.16.101:9092',\n",
    "        'group.id': 'traffic'}\n",
    "\n",
    "consumer = Consumer(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cdccb22-46c0-4826-9a8e-f8864e90dac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'traffic': <Future at 0x27362457210 state=running>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kadmin.describe_consumer_groups(['traffic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "265ffd4b-cab8-45f7-9d36-787d271c9948",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No msg\n"
     ]
    }
   ],
   "source": [
    "consumer.subscribe(['traffic_data_group7'])\n",
    "\n",
    "msg = consumer.poll(timeout=1.0)\n",
    "\n",
    "if msg is not None and msg.error():\n",
    "    if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "        # End of partition event\n",
    "        sys.stderr.write('%% %s [%d] reached end at offset %d\\n' %\n",
    "                         (msg.topic(), msg.partition(), msg.offset()))\n",
    "    # elif msg.error():\n",
    "        raise KafkaException(msg.error())\n",
    "elif msg is not None:\n",
    "    print(msg.value())\n",
    "else:\n",
    "    print('No msg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3635beb7-9cd1-44c1-a266-5eec9acd407d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
